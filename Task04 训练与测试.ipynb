{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6、训练与测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.1 模型训练\n",
    "前面的章节，我们已经对目标检测训练的各个重要的知识点进行了讲解，下面我们需要将整个流程串起来，对模型进行训练。\n",
    "\n",
    "目标检测网络的训练大致是如下的流程：\n",
    "\n",
    "+ 设置各种超参数\n",
    "+ 定义数据加载模块 dataloader\n",
    "+ 定义网络 model\n",
    "+ 定义损失函数 loss\n",
    "+ 定义优化器 optimizer\n",
    "+ 遍历训练数据，预测-计算loss-反向传播\n",
    "\n",
    "首先，我们导入必要的库，然后设定各种超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                                                                                                                                    \n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from model import tiny_detector, MultiBoxLoss\n",
    "from datasets import PascalVOCDataset\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Data parameters\n",
    "data_folder = '../../../dataset/VOCdevkit'  # data files root path\n",
    "keep_difficult = True  # use objects considered difficult to detect?\n",
    "n_classes = len(label_map)  # number of different types of objects\n",
    "\n",
    "# Learning parameters\n",
    "total_epochs = 230 # number of epochs to train\n",
    "batch_size = 32  # batch size\n",
    "workers = 4  # number of workers for loading data in the DataLoader\n",
    "print_freq = 100  # print training status every __ batches\n",
    "lr = 1e-3  # learning rate\n",
    "decay_lr_at = [150, 190]  # decay learning rate after these many epochs\n",
    "decay_lr_to = 0.1  # decay learning rate to this fraction of the existing learning rate\n",
    "momentum = 0.9  # momentum\n",
    "weight_decay = 5e-4  # weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照上面梳理的流程，编写训练代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Training.\n",
    "    \"\"\"\n",
    "    # Initialize model and optimizer\n",
    "    model = tiny_detector(n_classes=n_classes)\n",
    "    criterion = MultiBoxLoss(priors_cxcy=model.priors_cxcy)\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(),\n",
    "                                lr=lr, \n",
    "                                momentum=momentum,\n",
    "                                weight_decay=weight_decay)\n",
    "\n",
    "    # Move to default device\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    # Custom dataloaders\n",
    "    train_dataset = PascalVOCDataset(data_folder,\n",
    "                                     split='train',\n",
    "                                     keep_difficult=keep_difficult)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,   \n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=True,\n",
    "                                    collate_fn=train_dataset.collate_fn, \n",
    "                                    num_workers=workers,\n",
    "                                    pin_memory=True) \n",
    "\n",
    "    # Epochs\n",
    "    for epoch in range(total_epochs):\n",
    "        # Decay learning rate at particular epochs\n",
    "        if epoch in decay_lr_at:\n",
    "            adjust_learning_rate(optimizer, decay_lr_to)\n",
    "\n",
    "        # One epoch's training                                                                                                                 \n",
    "        train(train_loader=train_loader,\n",
    "              model=model,\n",
    "              criterion=criterion,\n",
    "              optimizer=optimizer,\n",
    "              epoch=epoch)\n",
    "\n",
    "        # Save checkpoint\n",
    "        save_checkpoint(epoch, model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，我们对单个epoch的训练逻辑进行了封装，其具体实现如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    One epoch's training.\n",
    "\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param model: model\n",
    "    :param criterion: MultiBox loss\n",
    "    :param optimizer: optimizer\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "    model.train()  # training mode enables dropout\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Batches\n",
    "    for i, (images, boxes, labels, _) in enumerate(train_loader):\n",
    "        data_time.update(time.time() - start)\n",
    "\n",
    "        # Move to default device\n",
    "        images = images.to(device)  # (batch_size (N), 3, 224, 224)\n",
    "        boxes = [b.to(device) for b in boxes]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "\n",
    "        # Forward prop.\n",
    "        predicted_locs, predicted_scores = model(images)  # (N, 441, 4), (N, 441, n_classes)\n",
    "\n",
    "        # Loss\n",
    "        loss = criterion(predicted_locs, predicted_scores, boxes, labels)  # scalar\n",
    "\n",
    "        # Backward prop.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(epoch,\n",
    "                                                                  i, \n",
    "                                                                  len(train_loader),\n",
    "                                                                  batch_time=batch_time,\n",
    "                                                                  data_time=data_time, \n",
    "                                                                  loss=losses))\n",
    "    del predicted_locs, predicted_scores, images, boxes, labels  # free some memory since their histories may be stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完成了代码的编写后，我们就可以开始训练模型了，训练过程类似下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ python train.py \n",
    "\n",
    "Loaded base model.\n",
    "\n",
    "Epoch: [0][0/518]    Batch Time 6.556 (6.556)    Data Time 3.879 (3.879)    Loss 27.7129 (27.7129)    \n",
    "Epoch: [0][100/518]    Batch Time 0.185 (0.516)    Data Time 0.000 (0.306)    Loss 6.1569 (8.4569)    \n",
    "Epoch: [0][200/518]    Batch Time 1.251 (0.487)    Data Time 1.065 (0.289)    Loss 6.3175 (7.3364)    \n",
    "Epoch: [0][300/518]    Batch Time 1.207 (0.476)    Data Time 1.019 (0.282)    Loss 5.6598 (6.9211)    \n",
    "Epoch: [0][400/518]    Batch Time 1.174 (0.470)    Data Time 0.988 (0.278)    Loss 6.2519 (6.6751)    \n",
    "Epoch: [0][500/518]    Batch Time 1.303 (0.468)    Data Time 1.117 (0.276)    Loss 5.4864 (6.4894)    \n",
    "Epoch: [1][0/518]    Batch Time 1.061 (1.061)    Data Time 0.871 (0.871)    Loss 5.7480 (5.7480)    \n",
    "Epoch: [1][100/518]    Batch Time 0.189 (0.227)    Data Time 0.000 (0.037)    Loss 5.8557 (5.6431)    \n",
    "Epoch: [1][200/518]    Batch Time 0.188 (0.225)    Data Time 0.000 (0.036)    Loss 5.2024 (5.5586)    \n",
    "Epoch: [1][300/518]    Batch Time 0.190 (0.225)    Data Time 0.000 (0.036)    Loss 5.5348 (5.4957)    \n",
    "Epoch: [1][400/518]    Batch Time 0.188 (0.226)    Data Time 0.000 (0.036)    Loss 5.2623 (5.4442)    \n",
    "Epoch: [1][500/518]    Batch Time 0.190 (0.225)    Data Time 0.000 (0.035)    Loss 5.3105 (5.3835)    \n",
    "Epoch: [2][0/518]    Batch Time 1.156 (1.156)    Data Time 0.967 (0.967)    Loss 5.3755 (5.3755)    \n",
    "Epoch: [2][100/518]    Batch Time 0.206 (0.232)    Data Time 0.016 (0.042)    Loss 5.6532 (5.1418)    \n",
    "Epoch: [2][200/518]    Batch Time 0.197 (0.226)    Data Time 0.007 (0.036)    Loss 4.6704 (5.0717)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.2 后处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2.1 目标框信息解码\n",
    "NMS的大致算法步骤如下：\n",
    "\n",
    "1. 按照类别分组，依次遍历每个类别。\n",
    "\n",
    "2. 当前类别按分类置信度排序，并且设置一个最低置信度阈值如0.05，低于这个阈值的目标框直接舍弃。\n",
    "\n",
    "3. 当前概率最高的框作为候选框，其它所有与候选框的IOU高于一个阈值（自己设定，如0.5）的框认为需要被抑制，从剩余框数组中删除。\n",
    "\n",
    "4. 然后在剩余的框里寻找概率第二大的框，其它所有与第二大的框的IOU高于设定阈值的框被抑制。\n",
    "\n",
    "依次类推重复这个过程，直至遍历完所有剩余框，所有没被抑制的框即为最终检测框。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.2.3 代码实现:\n",
    "整个后处理过程的代码实现位于model.py中tiny_detector类的detect_objects函数中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(self, predicted_locs, predicted_scores, min_score, max_overlap, top_k):\n",
    "    \"\"\"                                                                                                                                                       \n",
    "    Decipher the 441 locations and class scores (output of the tiny_detector) to detect objects.\n",
    "\n",
    "    For each class, perform Non-Maximum Suppression (NMS) on boxes that are above a minimum threshold.\n",
    "\n",
    "    :param predicted_locs: predicted locations/boxes w.r.t the 441 prior boxes, a tensor of dimensions (N, 441, 4)\n",
    "    :param predicted_scores: class scores for each of the encoded locations/boxes, a tensor of dimensions (N, 441, n_classes)\n",
    "    :param min_score: minimum threshold for a box to be considered a match for a certain class\n",
    "    :param max_overlap: maximum overlap two boxes can have so that the one with the lower score is not suppressed via NMS\n",
    "    :param top_k: if there are a lot of resulting detection across all classes, keep only the top 'k'\n",
    "    :return: detections (boxes, labels, and scores), lists of length batch_size\n",
    "    \"\"\"\n",
    "    batch_size = predicted_locs.size(0)\n",
    "    n_priors = self.priors_cxcy.size(0)\n",
    "    predicted_scores = F.softmax(predicted_scores, dim=2)  # (N, 441, n_classes)\n",
    "\n",
    "    # Lists to store final predicted boxes, labels, and scores for all images in batch\n",
    "    all_images_boxes = list()\n",
    "    all_images_labels = list()\n",
    "    all_images_scores = list()\n",
    "\n",
    "    assert n_priors == predicted_locs.size(1) == predicted_scores.size(1)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        # Decode object coordinates from the form we regressed predicted boxes to\n",
    "        decoded_locs = cxcy_to_xy(                                                                                                                            \n",
    "            gcxgcy_to_cxcy(predicted_locs[i], self.priors_cxcy))  # (441, 4), these are fractional pt. coordinates\n",
    "\n",
    "        # Lists to store boxes and scores for this image\n",
    "        image_boxes = list()\n",
    "        image_labels = list()\n",
    "        image_scores = list()\n",
    "\n",
    "        max_scores, best_label = predicted_scores[i].max(dim=1)  # (441)\n",
    "\n",
    "        # Check for each class\n",
    "        for c in range(1, self.n_classes):\n",
    "            # Keep only predicted boxes and scores where scores for this class are above the minimum score\n",
    "            class_scores = predicted_scores[i][:, c]  # (441)\n",
    "            score_above_min_score = class_scores > min_score  # torch.uint8 (byte) tensor, for indexing\n",
    "            n_above_min_score = score_above_min_score.sum().item()\n",
    "            if n_above_min_score == 0:\n",
    "                continue\n",
    "            class_scores = class_scores[score_above_min_score]  # (n_qualified), n_min_score <= 441\n",
    "            class_decoded_locs = decoded_locs[score_above_min_score]  # (n_qualified, 4)\n",
    "\n",
    "            # Sort predicted boxes and scores by scores\n",
    "            class_scores, sort_ind = class_scores.sort(dim=0, descending=True)  # (n_qualified), (n_min_score)\n",
    "            class_decoded_locs = class_decoded_locs[sort_ind]  # (n_min_score, 4)\n",
    "\n",
    "            # Find the overlap between predicted boxes\n",
    "            overlap = find_jaccard_overlap(class_decoded_locs, class_decoded_locs)  # (n_qualified, n_min_score)\n",
    "\n",
    "            # Non-Maximum Suppression (NMS)\n",
    "\n",
    "            # A torch.uint8 (byte) tensor to keep track of which predicted boxes to suppress\n",
    "            # 1 implies suppress, 0 implies don't suppress\n",
    "            suppress = torch.zeros((n_above_min_score), dtype=torch.uint8).to(device)  # (n_qualified)\n",
    "\n",
    "            # Consider each box in order of decreasing scores\n",
    "            for box in range(class_decoded_locs.size(0)):\n",
    "                # If this box is already marked for suppression\n",
    "                if suppress[box] == 1:\n",
    "                    continue\n",
    "\n",
    "                # Suppress boxes whose overlaps (with current box) are greater than maximum overlap\n",
    "                # Find such boxes and update suppress indices\n",
    "                suppress = torch.max(suppress, (overlap[box] > max_overlap).to(torch.uint8))\n",
    "                # The max operation retains previously suppressed boxes, like an 'OR' operation\n",
    "\n",
    "                # Don't suppress this box, even though it has an overlap of 1 with itself\n",
    "                suppress[box] = 0\n",
    "\n",
    "            # Store only unsuppressed boxes for this class\n",
    "            image_boxes.append(class_decoded_locs[1 - suppress])\n",
    "            image_labels.append(torch.LongTensor((1 - suppress).sum().item() * [c]).to(device))\n",
    "            image_scores.append(class_scores[1 - suppress])\n",
    "\n",
    "        # If no object in any class is found, store a placeholder for 'background'\n",
    "        if len(image_boxes) == 0:\n",
    "            image_boxes.append(torch.FloatTensor([[0., 0., 1., 1.]]).to(device))\n",
    "            image_labels.append(torch.LongTensor([0]).to(device))\n",
    "            image_scores.append(torch.FloatTensor([0.]).to(device))\n",
    "\n",
    "        # Concatenate into single tensors\n",
    "        image_boxes = torch.cat(image_boxes, dim=0)  # (n_objects, 4)\n",
    "        image_labels = torch.cat(image_labels, dim=0)  # (n_objects)\n",
    "        image_scores = torch.cat(image_scores, dim=0)  # (n_objects)\n",
    "        n_objects = image_scores.size(0)\n",
    "\n",
    "        # Keep only the top k objects\n",
    "        if n_objects > top_k:\n",
    "            image_scores, sort_ind = image_scores.sort(dim=0, descending=True)\n",
    "            image_scores = image_scores[:top_k]  # (top_k)\n",
    "            image_boxes = image_boxes[sort_ind][:top_k]  # (top_k, 4)\n",
    "            image_labels = image_labels[sort_ind][:top_k]  # (top_k)\n",
    "\n",
    "        # Append to lists that store predicted boxes and scores for all images\n",
    "        all_images_boxes.append(image_boxes)\n",
    "        all_images_labels.append(image_labels)\n",
    "        all_images_scores.append(image_scores)\n",
    "\n",
    "    return all_images_boxes, all_images_labels, all_images_scores  # lists of length batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的后处理代码中NMS的部分着实有些绕，大家可以参考下Fast R-CNN中的NMS实现，更简洁清晰一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------\n",
    "# Fast R-CNN\n",
    "# Copyright (c) 2015 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "import numpy as np\n",
    "# dets: 检测的 boxes 及对应的 scores；\n",
    "# thresh: 设定的阈值\n",
    "\n",
    "def nms(dets,thresh):\n",
    "    # boxes 位置\n",
    "    x1 = dets[:,0] \n",
    "    y1 = dets[:,1] \n",
    "    x2 = dets[:,2]\n",
    "    y2 = dets[:,3]\n",
    "    # boxes scores\n",
    "    scores = dets[:,4]\n",
    "    areas = (x2-x1+1)*(y2-y1+1)   # 各box的面积\n",
    "    order = scores.argsort()[::-1]  # 分类置信度排序\n",
    "    keep = []                        # 记录保留下的 boxes\n",
    "    while order.size > 0:\n",
    "        i = order[0]               # score最大的box对应的 index\n",
    "        keep.append(i)        # 将本轮score最大的box的index保留\n",
    "        \\# 计算剩余 boxes 与当前 box 的重叠程度 IoU\n",
    "        xx1 = np.maximum(x1[i],x1[order[1:]])\n",
    "        yy1 = np.maximum(y1[i],y1[order[1:]])\n",
    "        xx2 = np.minimum(x2[i],x2[order[1:]])\n",
    "        yy2 = np.minimum(y2[i],y2[order[1:]])\n",
    "        w = np.maximum(0.0,xx2-xx1+1) # IoU\n",
    "        h = np.maximum(0.0,yy2-yy1+1)\n",
    "        inter = w*h\n",
    "        ovr = inter/(areas[i]+areas[order[1:]]-inter)\n",
    "        \\# 保留 IoU 小于设定阈值的 boxes\n",
    "        inds = np.where(ovr<=thresh)[0]\n",
    "        order = order[inds+1]\n",
    "    return keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.3 单图预测推理\n",
    "当模型已经训练完成后，下面我们来看下如何对单张图片进行推理，得到目标检测结果。\n",
    "\n",
    "首先我们需要导入必要的python包，然后加载训练好的模型权重。\n",
    "\n",
    "随后我们需要定义预处理函数。为了达到最好的预测效果，测试环节的预处理方案需要和训练时保持一致，仅去除掉数据增强相关的变换即可。\n",
    "\n",
    "因此，这里我们需要进行的预处理为：\n",
    "\n",
    "+ 将图片缩放为 224 * 224 的大小\n",
    "+ 转换为 Tensor 并除 255\n",
    "+ 进行减均值除方差的归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set detect transforms (It's important to be consistent with training)\n",
    "resize = transforms.Resize((224, 224))\n",
    "to_tensor = transforms.ToTensor()\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着我们就来进行推理，过程很简单，核心流程可以概括为：\n",
    "\n",
    "1. 读取一张图片\n",
    "2. 预处理\n",
    "3. 模型预测\n",
    "4. 对模型预测进行后处理\n",
    "核心代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the image\n",
    "image = normalize(to_tensor(resize(original_image)))\n",
    "\n",
    "# Move to default device\n",
    "image = image.to(device)\n",
    "\n",
    "# Forward prop.\n",
    "predicted_locs, predicted_scores = model(image.unsqueeze(0))\n",
    "\n",
    "# Post process, get the final detect objects from our tiny detector output\n",
    "det_boxes, det_labels, det_scores = model.detect_objects(predicted_locs, predicted_scores, min_score=min_score, max_overlap=max_overlap, top_k=top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6.4 VOC测试集评测\n",
    "### 3.6.4.1 介绍map指标\n",
    "### 3.6.4.2 Tiny-Detection VOC测试集评测\n",
    "运行 eval.py 脚本，评估模型在VOC2007测试集上的效果，结果如下：\n",
    "\n",
    "python eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ python eval.py\n",
    "...\n",
    "...\n",
    "Evaluating: 100%|███████████████████████████████| 78/78 [00:57<00:00,  1.35it/s]\n",
    "{'aeroplane': 0.6086561679840088,\n",
    " 'bicycle': 0.7144593596458435,\n",
    " 'bird': 0.5847545862197876,\n",
    " 'boat': 0.44902321696281433,\n",
    " 'bottle': 0.2160634696483612,\n",
    " 'bus': 0.7212041616439819,\n",
    " 'car': 0.629608154296875,\n",
    " 'cat': 0.8124480843544006,\n",
    " 'chair': 0.3599272668361664,\n",
    " 'cow': 0.5980824828147888,\n",
    " 'diningtable': 0.6459739804267883,\n",
    " 'dog': 0.7577021718025208,\n",
    " 'horse': 0.7861635088920593,\n",
    " 'motorbike': 0.702280580997467,\n",
    " 'person': 0.5821948051452637,\n",
    " 'pottedplant': 0.2793791592121124,\n",
    " 'sheep': 0.5655995607376099,\n",
    " 'sofa': 0.708049476146698,\n",
    " 'train': 0.7575671672821045,\n",
    " 'tvmonitor': 0.5641061663627625}\n",
    "\n",
    "Mean Average Precision (mAP): 0.602"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，模型的mAP得分为60.2，比经典的YOLO网络的63.4的得分稍低，得分还是说的过去的～\n",
    "\n",
    "同时，我们也可以观察到，某几个类别，例如bottle和pottedplant的检测效果是很差的，说明我们的模型对于小物体，较为密集的物体的检测是存在明显问题的。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
